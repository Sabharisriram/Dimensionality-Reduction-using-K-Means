{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Skeleton Code"
      ],
      "metadata": {
        "id": "vrJdqD8pkQAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import zipfile\n",
        "import io\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Function to download and load dataset\n",
        "def load_data():\n",
        "    page_url = 'https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones'\n",
        "    page_response = requests.get(page_url)\n",
        "    if page_response.status_code == 200:\n",
        "        soup = BeautifulSoup(page_response.content, 'html.parser')\n",
        "        download_link = soup.select_one('a[href$=\".zip\"]')['href']\n",
        "        full_download_url = 'https://archive.ics.uci.edu' + download_link\n",
        "        response = requests.get(full_download_url)\n",
        "        if response.status_code == 200:\n",
        "            with zipfile.ZipFile(io.BytesIO(response.content)) as outer_zip:\n",
        "                inner_zip_name = 'UCI HAR Dataset.zip'\n",
        "                with outer_zip.open(inner_zip_name) as inner_zip_file:\n",
        "                    with zipfile.ZipFile(io.BytesIO(inner_zip_file.read())) as inner_zip:\n",
        "                        with inner_zip.open('UCI HAR Dataset/train/X_train.txt') as myfile:\n",
        "                            df = pd.read_csv(myfile, delim_whitespace=True, header=None)\n",
        "                        with inner_zip.open('UCI HAR Dataset/train/y_train.txt') as myfile_y:\n",
        "                            y = pd.read_csv(myfile_y, delim_whitespace=True, header=None)\n",
        "    else:\n",
        "        raise Exception(\"Failed to download or parse the dataset.\")\n",
        "    return df, y"
      ],
      "metadata": {
        "id": "6Ffvx4__VXbF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load dataset\n",
        "df, y = load_data()\n",
        "\n",
        "#TASK 1 - DO EDA and understand a little about the data.\n",
        "#Only important thing is to know that it has a lot of features that don't make sense, just a\n",
        "#bunch of readings from sensors.\n",
        "#We think many of these features are redundant or irrelevant, and we want to find good features.\n",
        "\n",
        "\n",
        "# 1. Display basic information about the DataFrame\n",
        "print(df.info())\n",
        "\n",
        "# 2. Check for missing values\n",
        "print(df.isnull().sum().sum())\n",
        "\n",
        "# 3. Descriptive statistics\n",
        "print(df.describe())\n",
        "\n",
        "# 4. Examine the target variable (y)\n",
        "print(y.value_counts())\n",
        "\n",
        "# 5. Correlation analysis (if applicable, consider only numerical features)\n",
        "# Correlation matrix\n",
        "print(df.corr())\n",
        "\n",
        "# 6. Feature importance based on variance\n",
        "# Calculate the variance of each feature.\n",
        "variances = df.var(axis=0)\n",
        "\n",
        "# Print or plot the variances.\n",
        "print(\"Feature variances:\")\n",
        "variances\n"
      ],
      "metadata": {
        "id": "CzSu3aGmiwPA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0579198-6acd-4093-af93-b1d0ed3ea90f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-836ccc4d8ebc>:30: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  df = pd.read_csv(myfile, delim_whitespace=True, header=None)\n",
            "<ipython-input-16-836ccc4d8ebc>:32: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  y = pd.read_csv(myfile_y, delim_whitespace=True, header=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7352 entries, 0 to 7351\n",
            "Columns: 561 entries, 0 to 560\n",
            "dtypes: float64(561)\n",
            "memory usage: 31.5 MB\n",
            "None\n",
            "0\n",
            "               0            1            2            3            4    \\\n",
            "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000   \n",
            "mean      0.274488    -0.017695    -0.109141    -0.605438    -0.510938   \n",
            "std       0.070261     0.040811     0.056635     0.448734     0.502645   \n",
            "min      -1.000000    -1.000000    -1.000000    -1.000000    -0.999873   \n",
            "25%       0.262975    -0.024863    -0.120993    -0.992754    -0.978129   \n",
            "50%       0.277193    -0.017219    -0.108676    -0.946196    -0.851897   \n",
            "75%       0.288461    -0.010783    -0.097794    -0.242813    -0.034231   \n",
            "max       1.000000     1.000000     1.000000     1.000000     0.916238   \n",
            "\n",
            "               5            6            7            8            9    ...  \\\n",
            "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000  ...   \n",
            "mean     -0.604754    -0.630512    -0.526907    -0.606150    -0.468604  ...   \n",
            "std       0.418687     0.424073     0.485942     0.414122     0.544547  ...   \n",
            "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  ...   \n",
            "25%      -0.980233    -0.993591    -0.978162    -0.980251    -0.936219  ...   \n",
            "50%      -0.859365    -0.950709    -0.857328    -0.857143    -0.881637  ...   \n",
            "75%      -0.262415    -0.292680    -0.066701    -0.265671    -0.017129  ...   \n",
            "max       1.000000     1.000000     0.967664     1.000000     1.000000  ...   \n",
            "\n",
            "               551          552          553          554          555  \\\n",
            "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000   \n",
            "mean      0.125293    -0.307009    -0.625294     0.008684     0.002186   \n",
            "std       0.250994     0.321011     0.307584     0.336787     0.448306   \n",
            "min      -1.000000    -0.995357    -0.999765    -0.976580    -1.000000   \n",
            "25%      -0.023692    -0.542602    -0.845573    -0.121527    -0.289549   \n",
            "50%       0.134000    -0.343685    -0.711692     0.009509     0.008943   \n",
            "75%       0.289096    -0.126979    -0.503878     0.150865     0.292861   \n",
            "max       0.946700     0.989538     0.956845     1.000000     1.000000   \n",
            "\n",
            "               556          557          558          559          560  \n",
            "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000  \n",
            "mean      0.008726    -0.005981    -0.489547     0.058593    -0.056515  \n",
            "std       0.608303     0.477975     0.511807     0.297480     0.279122  \n",
            "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  \n",
            "25%      -0.482273    -0.376341    -0.812065    -0.017885    -0.143414  \n",
            "50%       0.008735    -0.000368    -0.709417     0.182071     0.003181  \n",
            "75%       0.506187     0.359368    -0.509079     0.248353     0.107659  \n",
            "max       0.998702     0.996078     1.000000     0.478157     1.000000  \n",
            "\n",
            "[8 rows x 561 columns]\n",
            "0\n",
            "6    1407\n",
            "5    1374\n",
            "4    1286\n",
            "1    1226\n",
            "2    1073\n",
            "3     986\n",
            "Name: count, dtype: int64\n",
            "          0         1         2         3         4         5         6    \\\n",
            "0    1.000000  0.148061 -0.256952  0.000619 -0.021903 -0.044617  0.006290   \n",
            "1    0.148061  1.000000 -0.078769 -0.045160 -0.044920 -0.049746 -0.044180   \n",
            "2   -0.256952 -0.078769  1.000000 -0.020217 -0.016641 -0.008410 -0.018747   \n",
            "3    0.000619 -0.045160 -0.020217  1.000000  0.927461  0.851668  0.998632   \n",
            "4   -0.021903 -0.044920 -0.016641  0.927461  1.000000  0.895510  0.922803   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "556  0.037444  0.017967 -0.063609  0.018985 -0.008507 -0.018429  0.019389   \n",
            "557  0.028844  0.075679 -0.034037 -0.024810 -0.014592 -0.006471 -0.024951   \n",
            "558 -0.035257 -0.005309  0.008587 -0.371653 -0.380531 -0.345011 -0.368191   \n",
            "559  0.034371  0.001053 -0.015288  0.471065  0.523600  0.476006  0.466424   \n",
            "560  0.028242 -0.013903 -0.022643  0.394825  0.433169  0.482828  0.390922   \n",
            "\n",
            "          7         8         9    ...       551       552       553  \\\n",
            "0   -0.022754 -0.047558  0.044062  ...  0.030681 -0.017557 -0.015613   \n",
            "1   -0.045049 -0.050402 -0.038108  ... -0.022395 -0.001587 -0.004459   \n",
            "2   -0.015203 -0.001988 -0.037197  ... -0.020481  0.020091  0.019127   \n",
            "3    0.920888  0.846392  0.980844  ... -0.065987  0.148034  0.115565   \n",
            "4    0.997347  0.894509  0.917366  ... -0.105621  0.206227  0.176946   \n",
            "..        ...       ...       ...  ...       ...       ...       ...   \n",
            "556 -0.012546 -0.023525  0.025066  ... -0.026615  0.034514  0.024553   \n",
            "557 -0.012341 -0.007231 -0.028871  ...  0.000102 -0.017937 -0.014865   \n",
            "558 -0.377025 -0.347389 -0.384192  ...  0.087332 -0.086006 -0.079751   \n",
            "559  0.525081  0.477607  0.480229  ... -0.100125  0.086993  0.078079   \n",
            "560  0.431459  0.479751  0.405023  ... -0.057468  0.057831  0.052548   \n",
            "\n",
            "          554       555       556       557       558       559       560  \n",
            "0   -0.544320  0.012173  0.037444  0.028844 -0.035257  0.034371  0.028242  \n",
            "1    0.070559 -0.013541  0.017967  0.075679 -0.005309  0.001053 -0.013903  \n",
            "2    0.052841 -0.039836 -0.063609 -0.034037  0.008587 -0.015288 -0.022643  \n",
            "3   -0.035011 -0.021633  0.018985 -0.024810 -0.371653  0.471065  0.394825  \n",
            "4   -0.020379 -0.012505 -0.008507 -0.014592 -0.380531  0.523600  0.433169  \n",
            "..        ...       ...       ...       ...       ...       ...       ...  \n",
            "556 -0.006269  0.009141  1.000000 -0.116001 -0.005853 -0.012313 -0.019903  \n",
            "557 -0.020823  0.035263 -0.116001  1.000000  0.023995 -0.005869 -0.005656  \n",
            "558  0.011880  0.023246 -0.005853  0.023995  1.000000 -0.783848 -0.643655  \n",
            "559  0.001540 -0.012990 -0.012313 -0.005869 -0.783848  1.000000  0.594885  \n",
            "560 -0.003069 -0.017520 -0.019903 -0.005656 -0.643655  0.594885  1.000000  \n",
            "\n",
            "[561 rows x 561 columns]\n",
            "Feature variances:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.004937\n",
              "1      0.001665\n",
              "2      0.003208\n",
              "3      0.201363\n",
              "4      0.252652\n",
              "         ...   \n",
              "556    0.370032\n",
              "557    0.228460\n",
              "558    0.261946\n",
              "559    0.088494\n",
              "560    0.077909\n",
              "Length: 561, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.004937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.201363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.252652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>0.370032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>0.228460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>0.261946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>0.088494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>0.077909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>561 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Encode class labels\n",
        "# YOUR CODE HERE: Use LabelEncoder to encode class labels\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_y = label_encoder.fit_transform(y.values.ravel())"
      ],
      "metadata": {
        "id": "YrM7Un0yKi83"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Scale the features using StandardScaler\n",
        "# YOUR CODE HERE: Apply StandardScaler to df\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df)"
      ],
      "metadata": {
        "id": "7hSquwGocjTv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Split the data into training and testing sets\n",
        "# YOUR CODE HERE: Use train_test_split to split the data\n",
        "X_train_full, X_test_full, y_train, y_test = train_test_split(df_scaled, encoded_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "6Ji-3ztQc9T6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK 5 - 1. Create a pipeline using Gaussian Naive Bayes\n",
        "#         2. Fit the model to the training data\n",
        "#         3. Predict values for test set\n",
        "#         4. Print accuracy score\n",
        "\n",
        "#TASK 6 - 1. Note the start time before defining the pipeline\n",
        "#         2. Note the end time and report the difference as the time taken by the model training and inference.\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Note the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a pipeline with Gaussian Naive Bayes\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', GaussianNB())\n",
        "])\n",
        "\n",
        "# Fit the model to the training data\n",
        "pipeline.fit(X_train_full, y_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = pipeline.predict(X_test_full)\n",
        "\n",
        "# Print the accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Note the end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the time taken\n",
        "time_taken = end_time - start_time\n",
        "print(f\"Time taken for model training and inference: {time_taken} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6I-RbvyeS-G",
        "outputId": "9af82350-0c64-46ee-e96c-54c5f8d7c7ca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7314751869476547\n",
            "Time taken for model training and inference: 0.06807160377502441 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 7 - K-Means for dimensionality reduction\n",
        "n_clusters = 50\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "kmeans.fit(df_scaled.T)  # Transpose to treat features as data points\n",
        "selected_features_indices = [np.random.choice(np.where(kmeans.labels_ == i)[0]) for i in range(n_clusters)]\n",
        "selected_features = df_scaled[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "BL6sjs7khANa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK 8 - Train another model (GaussianNB) on the new dataset, and report time taken and accuracy\n",
        "\n",
        "# Split the data into training and testing sets using the selected features\n",
        "X_train, X_test, y_train, y_test = train_test_split(selected_features, encoded_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Note the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create and train a Gaussian Naive Bayes model\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_gnb = gnb.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "\n",
        "# Note the end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the time taken\n",
        "time_taken_gnb = end_time - start_time\n",
        "\n",
        "print(f\"GaussianNB Accuracy: {accuracy_gnb}\")\n",
        "print(f\"Time taken for GaussianNB model training and inference: {time_taken_gnb} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3gAhR0XyoE8",
        "outputId": "ce7c39fb-6435-43b2-f3bf-db6afbd297d5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GaussianNB Accuracy: 0.8028552005438477\n",
            "Time taken for GaussianNB model training and inference: 0.01118326187133789 seconds\n"
          ]
        }
      ]
    }
  ]
}